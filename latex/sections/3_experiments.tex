\section{Experiments}

\subsection{Setup}
List all:
\begin{itemize}
    \item What is the datasets,
    \item  models,
    \item CL setup: number of tasks,
    \item optimizers, hyper-param setup (details about the grid search over lr).
    \item Random label ( 100\%, 50\%, 20\%)
\end{itemize}
Also, mention why did you choose this particular setup.


\subsection{Results with Transformer (default setup)}

pretrain model,

\subsubsection{Effect of pre-training - pre trained bert}
\begin{itemize}
    \item Bert Model (pre-trained and no-pretrained)
    \item is that because of pretrained and non-pretrained
    \item is that because of transformers?
          % \item is that because of scale?
\end{itemize}
% --- is that because of pretrained and non-pretrained 

% --- is that because of transformers

\subsection{Ablations/Intervention/Analysis}

\subsubsection{Experiments for other type of networks: CNN, LSTM}
\begin{itemize}
    \item CNN on NLP results. Is there plasticity loss?
    \item LSTM on NLP results. Is there plasticity loss?
\end{itemize}

\subsection{Comparison with vision}

???


\subsubsection{self-attention vs MLP}
\begin{itemize}
    \item Self Attention Layer (Embedding + Multi-head Attention layer + Classifier)
    \item Self Attention Layer  with Residual Layer
    \item Bert Layer( Layer Norm and dropout)
\end{itemize}




